{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b62f95e5-61b2-412d-835f-43fc078867ba",
   "metadata": {},
   "source": [
    "# Стройка нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e13b39af-1d68-4841-a816-f82e48d4d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Operation():\n",
    "    '''\n",
    "    Базовый класс операций\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, input_: np.ndarray) -> np.ndarray:\n",
    "        \n",
    "        self.input_ = input_\n",
    "\n",
    "        self.output_ = self._output()\n",
    "        \n",
    "        return self.output_\n",
    "\n",
    "    def backward(self, output_diff: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        assert output_diff.shape[::-1] == self.output_.shape, f\"Output_diff_shape = {output_diff.shape}, Output_shape = {self.output_.shape}\"\n",
    "\n",
    "        return self._input_diff(output_diff)\n",
    "\n",
    "    def _output(self) -> np.ndarray:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def _input_diff(self, output_diff_):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e9f0457a-a5fa-493d-a90b-c25c1db7ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParamOperation(Operation):\n",
    "\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "\n",
    "    def backward(self, output_diff: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        assert output_diff.shape[::-1] == self.output_.shape, f\"Output_diff_shape = {output_diff.shape}, Output_shape = {self.output_.shape}\"\n",
    "        self.params_grad = self._params_grad(output_diff)\n",
    "        assert self.params_grad.shape == self.params.shape, f\"Params_grad_shape = {self.params_grad.shape}, Params_shape = {self.params.shape}\"\n",
    "        return self._input_diff(output_diff)\n",
    "\n",
    "    def _params_grad(self, output_diff_: np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "\n",
    "    def get_params_grad(self):\n",
    "        return self.params_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "66d0ea52-61ab-411d-b0df-3f629c5b9030",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightMultiply(ParamOperation):\n",
    "    \n",
    "    def _output(self):\n",
    "        assert self.params.shape[0] == self.input_.shape[1], f\"Params_shape = {self.params.shape}, Input_shape = {self.input_.shape}\"\n",
    "        return self.input_ @ self.params\n",
    "\n",
    "    def _input_diff(self, output_diff_: np.ndarray):\n",
    "        return self.params @ output_diff_\n",
    "\n",
    "    def _params_grad(self, output_diff_: np.ndarray):\n",
    "        return (output_diff_ @ self.input_).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2c37544c-399d-48ad-ae8f-f1ba6629b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasAdd(ParamOperation):\n",
    "\n",
    "    def __init__(self, B : np.ndarray):\n",
    "        super().__init__(B)\n",
    "    \n",
    "    def _output(self):\n",
    "        return self.input_ + self.params\n",
    "\n",
    "    def _input_diff(self, output_diff_: np.ndarray):\n",
    "        return output_diff_\n",
    "\n",
    "    def _params_grad(self, output_diff_: np.ndarray):\n",
    "        return np.sum(output_diff_.T, axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7ab5ea32-fb8b-4424-97fe-1cb7a8ce441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Operation):\n",
    "\n",
    "    def _sigmoid(self, input_ : np.ndarray):\n",
    "        return 1.0 / (1.0 + np.exp(np.clip(-input_, -50, 50)))\n",
    "\n",
    "    def _output(self):\n",
    "        return self._sigmoid(self.input_)\n",
    "\n",
    "    def _input_diff(self, output_diff_):\n",
    "        input_grad = (self.output_ * (1 - self.output_)).T * output_diff_\n",
    "        return input_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bb120816-7066-4f77-8fd2-9af66a0d4f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, neurons: int):\n",
    "        self.neurons = neurons\n",
    "        self.operations: List[Operation] = []\n",
    "        self.First = True\n",
    "\n",
    "    def setup_layer(self, shape):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, input_: np.ndarray):\n",
    "        self.input_ = input_\n",
    "        if self.First:\n",
    "            self.setup_layer(self.input_.shape)\n",
    "            self.First = False\n",
    "        self._output = input_\n",
    "        for operation in self.operations:\n",
    "            self._output = operation.forward(self._output)\n",
    "        \n",
    "        return self._output\n",
    "\n",
    "    def backward(self, output_diff):\n",
    "\n",
    "        self.input_grad = output_diff\n",
    "\n",
    "        for operation in self.operations[::-1]:\n",
    "            self.input_diff = operation.backward(self.input_grad)\n",
    "\n",
    "\n",
    "        return self.input_diff\n",
    "\n",
    "    def get_params(self):\n",
    "        for operation in self.operations:\n",
    "            if isinstance(operation, ParamOperation):\n",
    "                yield operation.get_params()\n",
    "\n",
    "    def get_params_grad(self):\n",
    "        for operation in self.operations:\n",
    "            if isinstance(operation, ParamOperation):\n",
    "                yield operation.get_params_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "60a7e79c-b4af-4b15-b39f-2285e27a178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    \n",
    "    def __init__(self, neurons, activation = Sigmoid):\n",
    "        super().__init__(neurons)\n",
    "        self.activation = activation\n",
    "\n",
    "    def setup_layer(self, shape):\n",
    "\n",
    "        W = np.random.randn(shape[1], self.neurons)\n",
    "        B = np.random.randn(1, self.neurons)\n",
    "        if self.activation is not None:\n",
    "            self.operations = [WeightMultiply(W),\n",
    "                              BiasAdd(B),\n",
    "                              self.activation()]\n",
    "        else:\n",
    "            self.operations = [WeightMultiply(W),\n",
    "                              BiasAdd(B)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "68b9986c-9efe-488a-9afa-abe313aaefe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, target, prediction):\n",
    "        self.target = target\n",
    "        self.prediction = prediction\n",
    "        assert self.target.shape == self.prediction.shape, f\"Target_shape = {self.target.shape}, Prediction_shape = {self.prediction.shape}\"\n",
    "        self.loss_value = self._output()\n",
    "        return self.loss_value\n",
    "\n",
    "    def backward(self):\n",
    "        self.prediction_diff_ = self.prediction_diff()\n",
    "        assert self.prediction_diff_.shape[::-1] == self.prediction.shape\n",
    "        return self.prediction_diff_\n",
    "\n",
    "    def _output(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def prediction_diff(self):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f9e17358-e711-42ae-8204-f9d07e34adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Loss):\n",
    "    \n",
    "    def _output(self):\n",
    "        return np.mean((self.target.reshape(self.prediction.shape) - self.prediction) ** 2)\n",
    "\n",
    "    def prediction_diff(self):\n",
    "        if self.prediction.ndim == 1:\n",
    "            return 2 / (self.prediction.shape[0] * self.prediction.shape[1]) * (self.prediction - self.target.reshape(self.prediction.shape)).reshape(-1, 1)\n",
    "        else:\n",
    "            return 2 / (self.prediction.shape[0] * self.prediction.shape[1]) * (self.prediction - self.target.reshape(self.prediction.shape)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3e8d0cea-935b-4c7f-9a44-ab6dad957c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class NeuralNetwork():\n",
    "    \n",
    "    def __init__(self, layers: List[Layer | Dense]):\n",
    "        self.layers = layers\n",
    "        \n",
    "    def forward(self, x_batch):\n",
    "\n",
    "        self.x_output = x_batch\n",
    "        for layer in self.layers:\n",
    "            self.x_output = layer.forward(self.x_output)\n",
    "        return self.x_output\n",
    "\n",
    "    def backward(self, loss_grad):\n",
    "\n",
    "        self.loss_grad = loss_grad\n",
    "\n",
    "        for layer in self.layers[::-1]:\n",
    "\n",
    "            self.loss_grad = layer.backward(self.loss_grad)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def get_params(self):\n",
    "        return map(lambda layer: layer.get_params(), self.layers)\n",
    "\n",
    "    def get_params_grad(self):\n",
    "        return map(lambda layer: layer.get_params_grad(), self.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31177ae-4649-4bd3-8ef7-ac98c8c90cab",
   "metadata": {},
   "source": [
    "## Реализация ранних моделей с помощью нового класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "84300933-00c9-4ca0-9b50-b4fdb0acd787",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "\n",
    "    def __init__(self, learning_rate = 0.01):\n",
    "\n",
    "        self.lr = learning_rate\n",
    "\n",
    "    def step(self):\n",
    "\n",
    "\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f016c603-8038-4d79-9a98-2ba7f552a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(Optimizer):\n",
    "\n",
    "    def step(self):\n",
    "        for layer_params, layer_params_grad in zip(self.net.get_params(), self.net.get_params_grad()): # type: ignore\n",
    "            for params, params_grad in zip(layer_params, layer_params_grad):\n",
    "                params -= self.lr * params_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0d5ee826-f4eb-477b-a71c-437b04282363",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, loss: Loss, Net: NeuralNetwork, optimizer, lr: float = 0.01):\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer(lr)\n",
    "        self.Net = Net\n",
    "        setattr(self.optimizer, 'net', self.Net)\n",
    "\n",
    "    def get_batch(self, x_train, y_train, batch_size):\n",
    "        N = x_train.shape[0]\n",
    "        for i in range(0, N, batch_size):\n",
    "            yield x_train[i:i + batch_size], y_train[i:i + batch_size]\n",
    "    \n",
    "    def fit(self, x_train, y_train, epochs = 100, verbose=True, batch_size = None):\n",
    "\n",
    "        np.random.seed(10)\n",
    "\n",
    "        indices = np.random.permutation(x_train.shape[0])\n",
    "        x_train = x_train[indices]\n",
    "        y_train = y_train[indices]\n",
    "\n",
    "        if batch_size is None:\n",
    "            batch_size = x_train.shape[0] // 5\n",
    "        \n",
    "        \n",
    "\n",
    "        for e in range(epochs):\n",
    "            all_loss = 0\n",
    "            for x_batch, y_batch in self.get_batch(x_train, y_train, batch_size):\n",
    "                pred = self.Net.forward(x_batch)\n",
    "                loss = self.loss.forward(y_batch, pred)\n",
    "                all_loss += loss\n",
    "                loss_grad = self.loss.backward()\n",
    "                self.Net.backward(loss_grad)\n",
    "                self.optimizer.step()\n",
    "\n",
    "            if verbose:\n",
    "                print(f'Epoch {e + 1}: loss = {all_loss * batch_size / x_train.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df55e8f-22ce-47b2-8ead-5ae32f75218e",
   "metadata": {},
   "source": [
    "## Тестирование классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b6130927-9c48-4c8e-974c-144f375c6f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "california = fetch_california_housing()\n",
    "x_train, x_test, y_train, y_test = train_test_split(california.data, california.target, random_state=10) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6cf7c220-0dc3-47fb-a57a-16babee3438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "x_train = sc.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4bac98a5-8586-4da5-b3a9-c29a406ace96",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestNetwork = NeuralNetwork(layers = [Dense(4), Dense(1, None)]) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8ffe7da7-d581-452f-9967-a61a339329a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TestTrainer = Trainer(MSE(), Linear_Regression, SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7d75a78f-1fca-404d-9759-cca823e868ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15480, 8)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "360f45f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss = 19.130741711848884\n",
      "Epoch 2: loss = 11.611255125032299\n",
      "Epoch 3: loss = 7.459053815558494\n",
      "Epoch 4: loss = 5.026573589031945\n",
      "Epoch 5: loss = 3.5536491192882433\n",
      "Epoch 6: loss = 2.6456083531499566\n",
      "Epoch 7: loss = 2.07962766325318\n",
      "Epoch 8: loss = 1.7233481303127938\n",
      "Epoch 9: loss = 1.4961224322529134\n",
      "Epoch 10: loss = 1.3483433355388446\n",
      "Epoch 11: loss = 1.249466568121682\n",
      "Epoch 12: loss = 1.1807434606490237\n",
      "Epoch 13: loss = 1.130720515106633\n",
      "Epoch 14: loss = 1.0924341490684712\n",
      "Epoch 15: loss = 1.0616648044845711\n",
      "Epoch 16: loss = 1.03585766176239\n",
      "Epoch 17: loss = 1.013461506153383\n",
      "Epoch 18: loss = 0.9935274319587077\n",
      "Epoch 19: loss = 0.9754671438109455\n",
      "Epoch 20: loss = 0.9589082140846347\n",
      "Epoch 21: loss = 0.9436077134734586\n",
      "Epoch 22: loss = 0.9294007546194287\n",
      "Epoch 23: loss = 0.916169830302018\n",
      "Epoch 24: loss = 0.9038265136248852\n",
      "Epoch 25: loss = 0.8923005086869517\n",
      "Epoch 26: loss = 0.8815330808504399\n",
      "Epoch 27: loss = 0.8714731055497758\n",
      "Epoch 28: loss = 0.8620746892391811\n",
      "Epoch 29: loss = 0.8532957377599744\n",
      "Epoch 30: loss = 0.8450970966582999\n",
      "Epoch 31: loss = 0.8374420360314848\n",
      "Epoch 32: loss = 0.830295941129006\n",
      "Epoch 33: loss = 0.8236261235929754\n",
      "Epoch 34: loss = 0.817401701113529\n",
      "Epoch 35: loss = 0.8115935136881347\n",
      "Epoch 36: loss = 0.8061740574709997\n",
      "Epoch 37: loss = 0.8011174252595822\n",
      "Epoch 38: loss = 0.7963992477261805\n",
      "Epoch 39: loss = 0.7919966326355884\n",
      "Epoch 40: loss = 0.7878881011754357\n",
      "Epoch 41: loss = 0.7840535216083614\n",
      "Epoch 42: loss = 0.7804740410311263\n",
      "Epoch 43: loss = 0.7771320162940202\n",
      "Epoch 44: loss = 0.7740109452242226\n",
      "Epoch 45: loss = 0.7710953992860378\n",
      "Epoch 46: loss = 0.7683709587334129\n",
      "Epoch 47: loss = 0.7658241511671725\n",
      "Epoch 48: loss = 0.7634423941823362\n",
      "Epoch 49: loss = 0.7612139424607747\n",
      "Epoch 50: loss = 0.7591278392358106\n",
      "Epoch 51: loss = 0.7571738715774451\n",
      "Epoch 52: loss = 0.7553425285196774\n",
      "Epoch 53: loss = 0.7536249608052698\n",
      "Epoch 54: loss = 0.7520129410709485\n",
      "Epoch 55: loss = 0.7504988236728193\n",
      "Epoch 56: loss = 0.7490755039763902\n",
      "Epoch 57: loss = 0.7477363776213932\n",
      "Epoch 58: loss = 0.7464753007954047\n",
      "Epoch 59: loss = 0.7452865527480914\n",
      "Epoch 60: loss = 0.744164801614661\n",
      "Epoch 61: loss = 0.7431050741906899\n",
      "Epoch 62: loss = 0.742102729782465\n",
      "Epoch 63: loss = 0.7411534378101532\n",
      "Epoch 64: loss = 0.740253158560882\n",
      "Epoch 65: loss = 0.73939812639019\n",
      "Epoch 66: loss = 0.7385848347114269\n",
      "Epoch 67: loss = 0.7378100222311799\n",
      "Epoch 68: loss = 0.7370706600298291\n",
      "Epoch 69: loss = 0.7363639392153418\n",
      "Epoch 70: loss = 0.7356872589807069\n",
      "Epoch 71: loss = 0.7350382149698276\n",
      "Epoch 72: loss = 0.734414587908142\n",
      "Epoch 73: loss = 0.7338143324889397\n",
      "Epoch 74: loss = 0.7332355665292072\n",
      "Epoch 75: loss = 0.7326765604230573\n",
      "Epoch 76: loss = 0.7321357269283207\n",
      "Epoch 77: loss = 0.7316116113239527\n",
      "Epoch 78: loss = 0.7311028819736327\n",
      "Epoch 79: loss = 0.7306083213254843\n",
      "Epoch 80: loss = 0.7301268173703235\n",
      "Epoch 81: loss = 0.7296573555724585\n",
      "Epoch 82: loss = 0.7291990112786483\n",
      "Epoch 83: loss = 0.7287509426031615\n",
      "Epoch 84: loss = 0.728312383780327\n",
      "Epoch 85: loss = 0.727882638970759\n",
      "Epoch 86: loss = 0.7274610765035783\n",
      "Epoch 87: loss = 0.7270471235343162\n",
      "Epoch 88: loss = 0.7266402610966063\n",
      "Epoch 89: loss = 0.7262400195250399\n",
      "Epoch 90: loss = 0.7258459742264737\n",
      "Epoch 91: loss = 0.7254577417774535\n",
      "Epoch 92: loss = 0.7250749763261232\n",
      "Epoch 93: loss = 0.7246973662778821\n",
      "Epoch 94: loss = 0.7243246312450714\n",
      "Epoch 95: loss = 0.7239565192420295\n",
      "Epoch 96: loss = 0.7235928041079323\n",
      "Epoch 97: loss = 0.7232332831408873\n",
      "Epoch 98: loss = 0.7228777749277653\n",
      "Epoch 99: loss = 0.7225261173552293\n",
      "Epoch 100: loss = 0.7221781657883491\n"
     ]
    }
   ],
   "source": [
    "TestNetwork = NeuralNetwork(layers = [Dense(4), Dense(1, None)]) # type: ignore\n",
    "TestTrainer = Trainer(MSE(), TestNetwork, SGD)\n",
    "TestTrainer.fit(x_train, y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3850e66f-6db3-4ace-8a25-a52cd820d925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss = 11.505606923326427\n",
      "Epoch 2: loss = 9.56118457035504\n",
      "Epoch 3: loss = 8.00089829788599\n",
      "Epoch 4: loss = 6.740473251327629\n",
      "Epoch 5: loss = 5.716263902100021\n",
      "Epoch 6: loss = 4.879666690671874\n",
      "Epoch 7: loss = 4.193172851988301\n",
      "Epoch 8: loss = 3.627552027905941\n",
      "Epoch 9: loss = 3.159821271214466\n",
      "Epoch 10: loss = 2.771764087724444\n",
      "Epoch 11: loss = 2.448838226777396\n",
      "Epoch 12: loss = 2.1793609606305395\n",
      "Epoch 13: loss = 1.9538945329177277\n",
      "Epoch 14: loss = 1.764777595499683\n",
      "Epoch 15: loss = 1.6057643195938047\n",
      "Epoch 16: loss = 1.4717438187094753\n",
      "Epoch 17: loss = 1.3585201365682409\n",
      "Epoch 18: loss = 1.2626383931669767\n",
      "Epoch 19: loss = 1.1812464607193267\n",
      "Epoch 20: loss = 1.1119842413499479\n",
      "Epoch 21: loss = 1.0528945681060364\n",
      "Epoch 22: loss = 1.0023511739669675\n",
      "Epoch 23: loss = 0.9590002237827404\n",
      "Epoch 24: loss = 0.9217126876926587\n",
      "Epoch 25: loss = 0.8895454255484136\n",
      "Epoch 26: loss = 0.8617093021407569\n",
      "Epoch 27: loss = 0.8375429994202586\n",
      "Epoch 28: loss = 0.8164914607550221\n",
      "Epoch 29: loss = 0.7980881126301932\n",
      "Epoch 30: loss = 0.7819401749866325\n",
      "Epoch 31: loss = 0.76771650290364\n",
      "Epoch 32: loss = 0.7551375072329989\n",
      "Epoch 33: loss = 0.7439667858841463\n",
      "Epoch 34: loss = 0.7340041651598681\n",
      "Epoch 35: loss = 0.7250799052465747\n",
      "Epoch 36: loss = 0.7170498683095964\n",
      "Epoch 37: loss = 0.7097914836939697\n",
      "Epoch 38: loss = 0.7032003741086285\n",
      "Epoch 39: loss = 0.6971875306632963\n",
      "Epoch 40: loss = 0.6916769442576777\n",
      "Epoch 41: loss = 0.6866036169120701\n",
      "Epoch 42: loss = 0.6819118898365574\n",
      "Epoch 43: loss = 0.6775540358941464\n",
      "Epoch 44: loss = 0.6734890730516815\n",
      "Epoch 45: loss = 0.6696817627798852\n",
      "Epoch 46: loss = 0.6661017634439874\n",
      "Epoch 47: loss = 0.6627229137500295\n",
      "Epoch 48: loss = 0.6595226254674934\n",
      "Epoch 49: loss = 0.6564813680903541\n",
      "Epoch 50: loss = 0.6535822309520051\n",
      "Epoch 51: loss = 0.6508105506779528\n",
      "Epoch 52: loss = 0.6481535938284303\n",
      "Epoch 53: loss = 0.6456002862206556\n",
      "Epoch 54: loss = 0.6431409817845358\n",
      "Epoch 55: loss = 0.6407672649432316\n",
      "Epoch 56: loss = 0.6384717814599016\n",
      "Epoch 57: loss = 0.6362480934860837\n",
      "Epoch 58: loss = 0.6340905552119211\n",
      "Epoch 59: loss = 0.6319942060755825\n",
      "Epoch 60: loss = 0.6299546789567697\n",
      "Epoch 61: loss = 0.627968121172081\n",
      "Epoch 62: loss = 0.6260311264205315\n",
      "Epoch 63: loss = 0.6241406761060062\n",
      "Epoch 64: loss = 0.6222940886983227\n",
      "Epoch 65: loss = 0.6204889759929895\n",
      "Epoch 66: loss = 0.6187232052975609\n",
      "Epoch 67: loss = 0.6169948667145975\n",
      "Epoch 68: loss = 0.6153022448117477\n",
      "Epoch 69: loss = 0.6136437940717767\n",
      "Epoch 70: loss = 0.612018117602351\n",
      "Epoch 71: loss = 0.6104239486594198\n",
      "Epoch 72: loss = 0.608860134601127\n",
      "Epoch 73: loss = 0.6073256229430303\n",
      "Epoch 74: loss = 0.6058194492313879\n",
      "Epoch 75: loss = 0.6043407264906121\n",
      "Epoch 76: loss = 0.6028886360346684\n",
      "Epoch 77: loss = 0.6014624194610667\n",
      "Epoch 78: loss = 0.6000613716708634\n",
      "Epoch 79: loss = 0.5986848347793735\n",
      "Epoch 80: loss = 0.59733219280059\n",
      "Epoch 81: loss = 0.5960028670040493\n",
      "Epoch 82: loss = 0.5946963118564546\n",
      "Epoch 83: loss = 0.5934120114720628\n",
      "Epoch 84: loss = 0.5921494765059345\n",
      "Epoch 85: loss = 0.590908241432868\n",
      "Epoch 86: loss = 0.5896878621623717\n",
      "Epoch 87: loss = 0.5884879139465535\n",
      "Epoch 88: loss = 0.5873079895434442\n",
      "Epoch 89: loss = 0.5861476976031621\n",
      "Epoch 90: loss = 0.5850066612485672\n",
      "Epoch 91: loss = 0.5838845168257247\n",
      "Epoch 92: loss = 0.5827809128026904\n",
      "Epoch 93: loss = 0.5816955087978983\n",
      "Epoch 94: loss = 0.5806279747218432\n",
      "Epoch 95: loss = 0.5795779900178318\n",
      "Epoch 96: loss = 0.5785452429894129\n",
      "Epoch 97: loss = 0.5775294302036589\n",
      "Epoch 98: loss = 0.5765302559608712\n",
      "Epoch 99: loss = 0.5755474318224613\n",
      "Epoch 100: loss = 0.5745806761898222\n"
     ]
    }
   ],
   "source": [
    "Linear_Regression = NeuralNetwork(layers = [Dense(neurons=1, activation=None)]) # type: ignore\n",
    "TestTrainer = Trainer(MSE(), Linear_Regression, SGD)\n",
    "TestTrainer.fit(x_train, y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "77ac7a25-2b1b-40d5-8831-3dc44abb88dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5160,), (5160,))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "x_test = sc.transform(x_test)\n",
    "y_pred = TestNetwork.forward(x_test).flatten()\n",
    "y_test.shape, y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f472031e-6a07-465a-bbe2-eaefbda432d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.7309265727536652\n"
     ]
    }
   ],
   "source": [
    "print('MSE:', mean_squared_error(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (envlab)",
   "language": "python",
   "name": "envlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
